{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12284656,"sourceType":"datasetVersion","datasetId":7742027},{"sourceId":12365601,"sourceType":"datasetVersion","datasetId":7796501}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.utils import Sequence, to_categorical","metadata":{"_uuid":"63ea33dd-bd60-42a1-bbf0-d14c28b02ad2","_cell_guid":"f4d13ea0-f86d-42cc-a66e-3c900e0847a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2025-07-04T06:38:22.938007Z","iopub.execute_input":"2025-07-04T06:38:22.938713Z","iopub.status.idle":"2025-07-04T06:38:22.943036Z","shell.execute_reply.started":"2025-07-04T06:38:22.938691Z","shell.execute_reply":"2025-07-04T06:38:22.942278Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"SCAN_DIR = '/kaggle/input/adni-processed/ADNI1_Processed'\nCSV_PATH = '/kaggle/input/scan-labels/ADNI1_Complete_1Yr_1.5T_6_20_2025.csv' ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:22.944554Z","iopub.execute_input":"2025-07-04T06:38:22.944791Z","iopub.status.idle":"2025-07-04T06:38:22.956085Z","shell.execute_reply.started":"2025-07-04T06:38:22.944767Z","shell.execute_reply":"2025-07-04T06:38:22.955520Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"IMG_SIZE = 224\nNUM_SLICES = 40\nBATCH_SIZE = 8\nEPOCHS = 5\n\n# Load CSV and create label map\ndf = pd.read_csv(CSV_PATH)\ndf['Subject'] = df['Subject'].astype(str).str.strip()\ndf['Group'] = df['Group'].astype(str).str.strip()\nlabel_map = dict(zip(df['Subject'], df['Group']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:22.956794Z","iopub.execute_input":"2025-07-04T06:38:22.957440Z","iopub.status.idle":"2025-07-04T06:38:22.977888Z","shell.execute_reply.started":"2025-07-04T06:38:22.957418Z","shell.execute_reply":"2025-07-04T06:38:22.977210Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"scan_paths, scan_labels = [], []\nfor root, _, files in os.walk(SCAN_DIR):\n    for file in files:\n        if file.endswith('.nii') or file.endswith('.nii.gz'):\n            full_path = os.path.join(root, file)\n            parts = full_path.split(os.sep)\n            try:\n                subj_id = parts[5]  # e.g., 133_S_0913 from /kaggle/input/adni-processed/ADNI1_Processed/133_S_0913/Ixxxx/file.nii\n                if subj_id in label_map:\n                    scan_paths.append(full_path)\n                    scan_labels.append(label_map[subj_id])\n            except IndexError:\n                continue\n\nprint(f\"✅ Total scans with labels: {len(scan_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:22.978488Z","iopub.execute_input":"2025-07-04T06:38:22.978657Z","iopub.status.idle":"2025-07-04T06:38:23.612208Z","shell.execute_reply.started":"2025-07-04T06:38:22.978644Z","shell.execute_reply":"2025-07-04T06:38:23.611483Z"}},"outputs":[{"name":"stdout","text":"✅ Total scans with labels: 459\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# Encode labels\nle = LabelEncoder()\nencoded_labels = le.fit_transform(scan_labels)\n\n# Train-test split\ntrain_paths, test_paths, y_train, y_test = train_test_split(\n    scan_paths, encoded_labels, test_size=0.2, random_state=42, stratify=encoded_labels\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:23.613890Z","iopub.execute_input":"2025-07-04T06:38:23.614096Z","iopub.status.idle":"2025-07-04T06:38:23.619939Z","shell.execute_reply.started":"2025-07-04T06:38:23.614081Z","shell.execute_reply":"2025-07-04T06:38:23.619358Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"def calculate_entropy(slice_2d):\n    histogram, _ = np.histogram(slice_2d, bins=256)\n    histogram = histogram / np.sum(histogram) + 1e-8\n    return -np.sum(histogram * np.log2(histogram))\n\ndef extract_top_slices(scan_path, num_slices=NUM_SLICES):\n    scan = nib.load(scan_path).get_fdata()\n    slice_entropies = [(i, calculate_entropy(scan[:, :, i])) for i in range(scan.shape[2])]\n    slice_entropies.sort(key=lambda x: x[1], reverse=True)\n    top_indices = [i for i, _ in slice_entropies[:num_slices]]\n    slices = [scan[:, :, i] for i in sorted(top_indices)]\n    slices = [np.stack([s]*3, axis=-1) for s in slices]  # Convert to RGB\n    resized = [tf.image.resize(s, (IMG_SIZE, IMG_SIZE)).numpy() for s in slices]\n    return np.stack(resized)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:23.620517Z","iopub.execute_input":"2025-07-04T06:38:23.620741Z","iopub.status.idle":"2025-07-04T06:38:23.628166Z","shell.execute_reply.started":"2025-07-04T06:38:23.620721Z","shell.execute_reply":"2025-07-04T06:38:23.627536Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"class ADNISequence(Sequence):\n    def __init__(self, paths, labels, batch_size=BATCH_SIZE, is_train=True):\n        self.paths = paths\n        self.labels = labels\n        self.batch_size = batch_size\n        self.is_train = is_train\n\n    def __len__(self):\n        return int(np.ceil(len(self.paths) / self.batch_size))\n\n    def __getitem__(self, idx):\n        batch_paths = self.paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n        X, y = [], []\n        for path, label in zip(batch_paths, batch_labels):\n            try:\n                slices = extract_top_slices(path)\n                X.append(slices)\n                y.extend([label] * slices.shape[0])\n            except Exception as e:\n                print(f\"Skipping {path}: {e}\")\n        X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n        y = to_categorical(np.array(y), num_classes=len(le.classes_))\n        return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:23.628878Z","iopub.execute_input":"2025-07-04T06:38:23.629462Z","iopub.status.idle":"2025-07-04T06:38:23.640505Z","shell.execute_reply.started":"2025-07-04T06:38:23.629445Z","shell.execute_reply":"2025-07-04T06:38:23.639807Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"def build_model(input_shape=(IMG_SIZE, IMG_SIZE, 3), num_classes=3):\n    base_model = VGG19(include_top=False, weights='imagenet', input_tensor=Input(shape=input_shape))\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    output = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=output)\n    for layer in base_model.layers:\n        layer.trainable = False\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:23.641192Z","iopub.execute_input":"2025-07-04T06:38:23.641376Z","iopub.status.idle":"2025-07-04T06:38:23.654015Z","shell.execute_reply.started":"2025-07-04T06:38:23.641360Z","shell.execute_reply":"2025-07-04T06:38:23.653295Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"train_gen = ADNISequence(train_paths, y_train)\ntest_gen = ADNISequence(test_paths, y_test, is_train=False)\nsteps_per_epoch = len(train_gen)\nvalidation_steps = len(test_gen)\n\n# Build and train\nmodel = build_model(num_classes=len(le.classes_))\nhistory = model.fit(\n    train_gen,\n    validation_data=test_gen,\n    epochs=10,\n    steps_per_epoch=len(train_gen),\n    validation_steps=len(test_gen)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T06:38:23.654890Z","iopub.execute_input":"2025-07-04T06:38:23.655535Z","iopub.status.idle":"2025-07-04T07:33:16.506747Z","shell.execute_reply.started":"2025-07-04T06:38:23.655512Z","shell.execute_reply":"2025-07-04T07:33:16.505902Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_24']\nReceived: inputs=Tensor(shape=(None, 224, 224, 3))\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 7s/step - accuracy: 0.3488 - loss: 1.6967 - val_accuracy: 0.4122 - val_loss: 1.1403\nEpoch 2/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 7s/step - accuracy: 0.4131 - loss: 1.1644 - val_accuracy: 0.4834 - val_loss: 1.1073\nEpoch 3/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 7s/step - accuracy: 0.4478 - loss: 1.1359 - val_accuracy: 0.4560 - val_loss: 1.0713\nEpoch 4/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 7s/step - accuracy: 0.4894 - loss: 1.0394 - val_accuracy: 0.3935 - val_loss: 1.1051\nEpoch 5/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 7s/step - accuracy: 0.4396 - loss: 1.0722 - val_accuracy: 0.4601 - val_loss: 1.0695\nEpoch 6/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 7s/step - accuracy: 0.4533 - loss: 1.0729 - val_accuracy: 0.4834 - val_loss: 1.1187\nEpoch 7/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m329s\u001b[0m 7s/step - accuracy: 0.5398 - loss: 0.9847 - val_accuracy: 0.4818 - val_loss: 1.0341\nEpoch 8/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 7s/step - accuracy: 0.5058 - loss: 0.9980 - val_accuracy: 0.3459 - val_loss: 1.1724\nEpoch 9/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 7s/step - accuracy: 0.4493 - loss: 1.0543 - val_accuracy: 0.5095 - val_loss: 1.0290\nEpoch 10/10\n\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 7s/step - accuracy: 0.4894 - loss: 1.0095 - val_accuracy: 0.4989 - val_loss: 1.0212\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"y_pred, y_true = [], []\nfor X_batch, y_batch in test_gen:\n    preds = model.predict(X_batch, verbose=0)\n    y_pred.extend(np.argmax(preds, axis=1))\n    y_true.extend(np.argmax(y_batch, axis=1))\n\nprint(\"\\n📊 Classification Report:\")\nprint(classification_report(y_true, y_pred, target_names=le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-04T07:33:16.507641Z","iopub.execute_input":"2025-07-04T07:33:16.507888Z","iopub.status.idle":"2025-07-04T07:34:36.127062Z","shell.execute_reply.started":"2025-07-04T07:33:16.507871Z","shell.execute_reply":"2025-07-04T07:34:36.125830Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\nExpected: ['keras_tensor_24']\nReceived: inputs=Tensor(shape=(32, 224, 224, 3))\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self._interrupted_warning()\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1101126170.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         outputs = tree.map_structure_up_to(\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotentially_ragged_concat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m         )\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_np_if_not_ragged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'batch_outputs' where it is not associated with a value"],"ename":"UnboundLocalError","evalue":"cannot access local variable 'batch_outputs' where it is not associated with a value","output_type":"error"}],"execution_count":62},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
