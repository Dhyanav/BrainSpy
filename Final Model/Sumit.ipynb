{"metadata":{"kernelspec":{"name":"","display_name":""},"language_info":{"name":""},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"4a253b05","cell_type":"markdown","source":"# Alzheimer's Classification on ADNI1_Preprocessed Dataset\nThis notebook trains LeNet and AlexNet models on the preprocessed MRI data located under `adni-processed/ADNI1_Processed/`.","metadata":{}},{"id":"e950b69f","cell_type":"code","source":"\nimport os\nimport numpy as np\nimport pandas as pd\nimport nibabel as nib\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization\nimport matplotlib.pyplot as plt\n","metadata":{},"outputs":[],"execution_count":null},{"id":"81671c2b","cell_type":"markdown","source":"## Load Diagnosis Metadata","metadata":{}},{"id":"05426e61","cell_type":"code","source":"\ndiagnosis_df = pd.read_csv('/kaggle/input/csv-file/ADNI1_Complete_1Yr_1.5T_6_20_2025.csv')\ndiagnosis_df = diagnosis_df[['Subject', 'Group']].drop_duplicates()\ndiagnosis_df = diagnosis_df[diagnosis_df['Group'].isin(['CN', 'MCI', 'AD'])]\ndiagnosis_map = dict(zip(diagnosis_df['Subject'], diagnosis_df['Group']))\nlabel_map = {'CN': 0, 'MCI': 1, 'AD': 2}\n","metadata":{},"outputs":[],"execution_count":null},{"id":"3048dfbe","cell_type":"markdown","source":"## Load and Preprocess Middle Slices from Preprocessed NIfTI Files","metadata":{}},{"id":"4d20f992","cell_type":"code","source":"\ndef load_middle_slice(path):\n    img = nib.load(path).get_fdata()\n    mid = img.shape[2] // 2\n    slice_img = img[:, :, mid]\n    slice_img = cv2.resize(slice_img, (64, 64))\n    slice_img = (slice_img - np.mean(slice_img)) / (np.std(slice_img) + 1e-8)\n    return np.expand_dims(slice_img, axis=-1)\n\nX = []\ny = []\n\ndata_dir = '/kaggle/input/adni-processed/ADNI1_Processed'\nfor subject_id in os.listdir(data_dir):\n    subj_path = os.path.join(data_dir, subject_id)\n    if subject_id not in diagnosis_map:\n        continue\n    label = label_map[diagnosis_map[subject_id]]\n    for subfolder, _, files in os.walk(subj_path):\n        for file in files:\n            if file.endswith('.nii') or file.endswith('.nii.gz'):\n                try:\n                    full_path = os.path.join(subfolder, file)\n                    img = load_middle_slice(full_path)\n                    X.append(img)\n                    y.append(label)\n                    break  # one scan per subject\n                except:\n                    continue\n\nX = np.array(X)\ny = to_categorical(np.array(y), num_classes=3)\nprint(f\"Loaded {X.shape[0]} samples with shape {X.shape[1:]}\")\n","metadata":{},"outputs":[],"execution_count":null},{"id":"7b9190c0","cell_type":"markdown","source":"## Train-Test Split","metadata":{}},{"id":"d3d91441","cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"b7e9bae4","cell_type":"markdown","source":"## LeNet Model","metadata":{}},{"id":"54151282","cell_type":"code","source":"\nlenet = Sequential([\n    Conv2D(6, kernel_size=5, activation='relu', input_shape=(64, 64, 1), padding='same'),\n    AveragePooling2D(pool_size=(2, 2)),\n    Conv2D(16, kernel_size=5, activation='relu'),\n    AveragePooling2D(pool_size=(2, 2)),\n    Flatten(),\n    Dense(120, activation='relu'),\n    Dense(84, activation='relu'),\n    Dense(3, activation='softmax')\n])\nlenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nlenet_history = lenet.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=16)\n","metadata":{},"outputs":[],"execution_count":null},{"id":"b9cd2d31","cell_type":"markdown","source":"## AlexNet Model","metadata":{}},{"id":"5b63e270","cell_type":"code","source":"\nalexnet = Sequential([\n    Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=(64, 64, 1), padding='same'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=3, strides=2),\n    Conv2D(256, (5, 5), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPooling2D(pool_size=3, strides=2),\n    Conv2D(384, (3, 3), activation='relu', padding='same'),\n    Conv2D(384, (3, 3), activation='relu', padding='same'),\n    Conv2D(256, (3, 3), activation='relu', padding='same'),\n    MaxPooling2D(pool_size=3, strides=2),\n    Flatten(),\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    Dense(4096, activation='relu'),\n    Dropout(0.5),\n    Dense(3, activation='softmax')\n])\nalexnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nalexnet_history = alexnet.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=16)\n","metadata":{},"outputs":[],"execution_count":null}]}
